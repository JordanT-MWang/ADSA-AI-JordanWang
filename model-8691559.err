Identity added: /home/jordanw7/.ssh/id_ed25519 (cluster_key)
2025-10-18 03:24:33.296541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-10-18 03:24:35.666403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-10-18 03:24:50.668765: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1760758211.496772 2245895 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22395 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:3d:00.0, compute capability: 8.0
2025-10-18 03:30:15.658642: I external/local_xla/xla/service/service.cc:163] XLA service 0x14c4400026d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2025-10-18 03:30:15.658720: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0
2025-10-18 03:30:15.820176: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2025-10-18 03:30:16.341318: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91301
2025-10-18 03:30:27.108954: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng17{k25=1} for conv (f32[16,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,512,640]{3,2,1,0}, f32[16,16,512,640]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false,"reification_cost":[]} is taking a while...
2025-10-18 03:30:28.123850: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2.014966167s
Trying algorithm eng17{k25=1} for conv (f32[16,1,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,512,640]{3,2,1,0}, f32[16,16,512,640]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false,"reification_cost":[]} is taking a while...
2025-10-18 03:30:30.415460: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng23{k2=6,k13=0,k14=2,k18=1,k23=0} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,512,640]{3,2,1,0}, f32[16,16,512,640]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false,"reification_cost":[]} is taking a while...
2025-10-18 03:30:30.423801: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.00840644s
Trying algorithm eng23{k2=6,k13=0,k14=2,k18=1,k23=0} for conv (f32[16,16,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,512,640]{3,2,1,0}, f32[16,16,512,640]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target="__cudnn$convBackwardFilter", backend_config={"operation_queue_id":"0","wait_on_operation_queues":[],"cudnn_conv_backend_config":{"activation_mode":"kNone","conv_result_scale":1,"side_input_scale":0,"leakyrelu_alpha":0},"force_earliest_schedule":false,"reification_cost":[]} is taking a while...
I0000 00:00:1760758234.758509 2246056 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
To github.com:JordanT-MWang/ADSA-AI-JordanWang.git
   713d512..0fd662e  main -> main
